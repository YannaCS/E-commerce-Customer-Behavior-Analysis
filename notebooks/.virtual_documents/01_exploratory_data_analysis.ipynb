


# Import essential libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# Set visualization styles
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")

# Configure pandas display options
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 100)
pd.set_option('display.float_format', lambda x: '%.2f' % x)





df = pd.read_csv('../data/raw/ecommerce_customer_churn_dataset.csv')

# Display basic information
print(f"Dataset Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns")
print(f"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")








# Display first 10 rows
df.head(10)





df.info()





# Descriptive statistics for numerical variables
df.describe()








# Display detailed column information
print("Column Name                    | Data Type  | Unique Values")
print("="*80)
for col in df.columns:
    print(f"{col:30s} | {str(df[col].dtype):10s} | {df[col].nunique():,}")








data_quality = []

for col in df.columns:
    col_info = {
        'Column': col,
        'Data_Type': str(df[col].dtype),
        'Missing_Count': df[col].isnull().sum(),
        'Missing_Pct': (df[col].isnull().sum() / len(df)) * 100,
        'Non_Null': df[col].notnull().sum(),
        'Unique_Values': df[col].nunique()
    }
    
    # Add range information based on data type
    if pd.api.types.is_numeric_dtype(df[col].dtype):
        # col_info['Min'] = df[col].min()
        # col_info['Max'] = df[col].max()
        col_info['Range'] = f"[{df[col].min():.2f} - {df[col].max():.2f}]"
    else:
        # col_info['Min'] = 'N/A'
        # col_info['Max'] = 'N/A'
        col_info['Range'] = f"{df[col].nunique()} categories"
    
    data_quality.append(col_info)

# Convert to DataFrame
quality_df = pd.DataFrame(data_quality)

# Separate columns with and without missing values
missing_cols = quality_df[quality_df['Missing_Count'] > 0].sort_values('Missing_Pct', ascending=False)

if len(missing_cols) > 0:
    print("\n‚ö†Ô∏è  COLUMNS WITH MISSING VALUES:")
    print(missing_cols.to_string(index=False))
    print(f"\nTotal columns with missing values: {len(missing_cols)}/{len(df.columns)}")
else:
    print("\n‚úÖ NO MISSING VALUES DETECTED!")
    print(f"\nAll {len(df.columns)} columns are complete with no missing values.")

# Summary statistics
total_missing = quality_df['Missing_Count'].sum()
total_cells = len(df) * len(df.columns)
overall_completeness = ((total_cells - total_missing) / total_cells) * 100

print("\n" + "="*100)
print("OVERALL DATA COMPLETENESS SUMMARY")
print(f"Total Cells: {total_cells:,}")
print(f"Missing Cells: {total_missing:,}")
print(f"Complete Cells: {(total_cells - total_missing):,}")
print(f"Overall Completeness: {overall_completeness:.2f}%")
print(f"Ratio of Records with Missing Value(s): {df.isnull().any(axis=1).mean() * 100:.2f}%")








import missingno as msno
# Figure 1: Missing Data Matrix
plt.figure(figsize=(20, 10))
msno.matrix(df, fontsize=16, sparkline=True)
plt.title('Missing Data Matrix - Distribution Across 50K Customer Records', 
          fontsize=16, fontweight='bold', pad=20)
plt.xlabel('Features', fontsize=14, fontweight='bold')
plt.ylabel('Customer Records', fontsize=14, fontweight='bold')
# plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig('../visualizations/missing_data_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# Figure 2: Missing Data Correlation Heatmap  
plt.figure(figsize=(14, 12))
msno.heatmap(df, fontsize=16, cmap='seismic', vmin=-0.2, vmax=0.2)
plt.title('Missing Data Correlation Heatmap - Feature Relationships', 
          fontsize=16, fontweight='bold', pad=20)
plt.xticks(rotation=45, ha='right', fontsize=14)
plt.yticks(rotation=0, fontsize=14)
plt.tight_layout()
plt.savefig('../visualizations/missing_correlation_heatmap.png', dpi=300, bbox_inches='tight')
plt.show()











# Store original shape for comparison
original_shape = df.shape
print(f"\nOriginal Dataset Shape: {original_shape[0]:,} rows √ó {original_shape[1]} columns")
# ============================================================================
# 1. Remove rows with >50% missing values
# Calculate missing percentage per row
missing_per_row = df.isnull().sum(axis=1) / df.shape[1] * 100

# Identify rows to remove
rows_to_remove = missing_per_row > 50
rows_removed_count = rows_to_remove.sum()

print(f"Rows with >50% missing values: {rows_removed_count:,} ({rows_removed_count/len(df)*100:.2f}%)")

if rows_removed_count > 0:
    # Remove rows
    df = df[~rows_to_remove].copy()
    print(f"‚úÖ Removed {rows_removed_count:,} rows")
    print(f"New shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns")
else:
    print("‚úÖ No rows need to be removed")

# ============================================================================
# 2. Fill "usage/engagement" metrics with 0
usage_engagement_cols = [
    'Social_Media_Engagement_Score',
    'Mobile_App_Usage',
    'Product_Reviews_Written',
    'Customer_Service_Calls',
    'Returns_Rate',
    'Wishlist_Items',
    'Days_Since_Last_Purchase'
]
# Check which columns actually exist in the dataset
existing_usage_cols = [col for col in usage_engagement_cols if col in df.columns]

print(f"Columns to fill with 0: {len(existing_usage_cols)}")
for col in existing_usage_cols:
    missing_before = df[col].isnull().sum()
    if missing_before > 0:
        df[col].fillna(0, inplace=True)
        print(f"  ‚Ä¢ {col:40s}: Filled {missing_before:,} missing values with 0")
    else:
        print(f"  ‚Ä¢ {col:40s}: No missing values (skipped)")

print(f"‚úÖ Filled {len(existing_usage_cols)} usage/engagement columns with 0")

# ============================================================================
# 3. Fill remaining columns with median
# Identify numerical columns that still have missing values
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
remaining_cols_with_missing = [col for col in numerical_cols 
                               if df[col].isnull().sum() > 0 
                               and col not in existing_usage_cols]

if len(remaining_cols_with_missing) > 0:
    print(f"Columns to fill with median: {len(remaining_cols_with_missing)}")
    
    for col in remaining_cols_with_missing:
        missing_before = df[col].isnull().sum()
        median_value = df[col].median()
        df[col].fillna(median_value, inplace=True)
        print(f"  ‚Ä¢ {col:40s}: Filled {missing_before:,} values with median ({median_value:.2f})")
    
    print(f"‚úÖ Filled {len(remaining_cols_with_missing)} columns with median")
else:
    print("‚úÖ No remaining numerical columns with missing values")

# ============================================================================
# 4. Handle categorical columns (if any remain)
print("\n" + "-"*100)

categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
categorical_missing = [col for col in categorical_cols if df[col].isnull().sum() > 0]

if len(categorical_missing) > 0:
    print(f"Categorical columns with missing values: {len(categorical_missing)}")
    
    for col in categorical_missing:
        missing_before = df[col].isnull().sum()
        mode_value = df[col].mode()[0] if len(df[col].mode()) > 0 else 'Unknown'
        df[col].fillna(mode_value, inplace=True)
        print(f"  ‚Ä¢ {col:40s}: Filled {missing_before:,} values with mode ('{mode_value}')")
    
    print(f"‚úÖ Filled {len(categorical_missing)} categorical columns with mode")
else:
    print("‚úÖ No categorical columns with missing values")

# ============================================================================
# 5. FINAL VERIFICATION
# Check for any remaining missing values
remaining_missing = df.isnull().sum()
total_remaining_missing = remaining_missing.sum()

if total_remaining_missing > 0:
    print(f"\n‚ö†Ô∏è  WARNING: {total_remaining_missing:,} missing values still remain!")
    print("\nColumns with remaining missing values:")
    remaining_missing_cols = remaining_missing[remaining_missing > 0]
    for col, count in remaining_missing_cols.items():
        print(f"  ‚Ä¢ {col:40s}: {count:,} missing values")
else:
    print("\n‚úÖ SUCCESS! All missing values have been handled!")

# ============================================================================
# SUMMARY STATISTICS
print("\n" + "="*100)
final_shape = df.shape

print(f"\nüìä Dataset Changes:")
print(f"  ‚Ä¢ Original shape:        {original_shape[0]:,} rows √ó {original_shape[1]} columns")
print(f"  ‚Ä¢ Final shape:           {final_shape[0]:,} rows √ó {final_shape[1]} columns")
print(f"  ‚Ä¢ Rows removed:          {original_shape[0] - final_shape[0]:,}")
print(f"  ‚Ä¢ Data retention:        {final_shape[0]/original_shape[0]*100:.2f}%")

print(f"\nüîß Treatment Applied:")
print(f"  ‚Ä¢ Rows deleted (>50% missing):              {rows_removed_count:,}")
print(f"  ‚Ä¢ Usage/engagement cols filled with 0:      {len(existing_usage_cols)}")
print(f"  ‚Ä¢ Numerical cols filled with median:        {len(remaining_cols_with_missing)}")
print(f"  ‚Ä¢ Categorical cols filled with mode:        {len(categorical_missing)}")

print(f"\n‚úÖ Data Quality Status:")
if total_remaining_missing == 0:
    print(f"  ‚Ä¢ Missing values:        0 (100% complete)")
    print(f"  ‚Ä¢ Status:                Ready for analysis ‚úì")
else:
    print(f"  ‚Ä¢ Missing values:        {total_remaining_missing:,}")
    print(f"  ‚Ä¢ Status:                Needs further attention ‚ö†Ô∏è")





duplicate_count = df.duplicated().sum()
duplicate_pct = (duplicate_count / len(df)) * 100

print(f"Duplicate Records: {duplicate_count:,}")
if duplicate_count > 0:
    print(f"Duplicate Percentage: {duplicate_pct:.2f}%")
    print("‚ö†Ô∏è  Recommendation: Consider removing duplicates")
else:
    print("‚úÖ No duplicate records found")


df.to_csv('../data/processed/cleaned.csv')





# categorize columns as numerical or categorical
numerical_cols = df.select_dtypes(include='number').columns.tolist()
categorical_cols = df.select_dtypes(exclude='number').columns.tolist()
# check 
print('numerical: ', numerical_cols)
print('\ncategorical: ', categorical_cols)


# remove 'Churned' from numerical_cols
numerical_cols.remove('Churned')
# add it to categorical
categorical_cols.append('Churned')
# check 
print('numerical: ', numerical_cols)
print('total numerical columns: ', len(numerical_cols))
print('\ncategorical: ', categorical_cols)
print('total categorical columns: ', len(categorical_cols))








if numerical_cols:
    stats_df = df[numerical_cols].describe().T
    stats_df['skewness'] = df[numerical_cols].skew()
    stats_df['kurtosis'] = df[numerical_cols].kurtosis()
    
    print("Detailed Statistics for Numerical Variables:")
display(stats_df)








if numerical_cols:
    n_cols = 4
    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5*n_rows))
    axes = axes.flatten() if len(numerical_cols) > 1 else [axes]

    for idx, col in enumerate(numerical_cols):
        ax = axes[idx]

        # Histogram + KDE with custom KDE color
        sns.histplot(
            data=df,
            x=col,
            bins=50,
            kde=True,
            stat="count",
            alpha=0.6,
            color="skyblue",
            edgecolor="black",
            line_kws={'color': '#FF6B6B', 'linewidth': 2},  # Light red KDE curve
            ax=ax
        )

        # Calculate statistics
        mean_val = df[col].mean()
        median_val = df[col].median()
        skew_val = df[col].skew()

        # Mean & Median lines
        ax.axvline(mean_val, color='green', linestyle='--', linewidth=2, 
                   label=f'Mean: {mean_val:.2f}')
        ax.axvline(median_val, color='orange', linestyle='--', linewidth=2,
                   label=f'Median: {median_val:.2f}')

        ax.set_title(f'{col}\n(Skewness: {skew_val:.2f})',
                     fontsize=12, fontweight='bold')
        ax.set_xlabel(col, fontsize=10)
        ax.set_ylabel("Frequency", fontsize=10)
        ax.legend(loc='upper right', fontsize=12)
        ax.grid(True, alpha=0.3)

    # Remove empty subplots
    for idx in range(len(numerical_cols), len(axes)):
        fig.delaxes(axes[idx])

    plt.tight_layout()
    plt.savefig('../visualizations/Numerical_Histogram', dpi=300, bbox_inches='tight')
    plt.show()





import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

sns.set_style("whitegrid")

if numerical_cols:
    n_cols = 4
    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols

    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 20))
    axes = axes.flatten() if len(numerical_cols) > 1 else [axes]

    for idx, col in enumerate(numerical_cols):
        ax = axes[idx]

        data = df[col].dropna()

        # Boxplot (same blue as histogram)
        sns.boxplot(
            y=data,
            ax=ax,
            color="skyblue",
            width=0.4,
            fliersize=4
        )

        # Average, Median line in green, orange (overlay)
        average_val = data.mean()
        ax.axhline(average_val, color="green", linestyle="--", linewidth=1,label=f"Median: {average_val:.2f}")
        median_val = data.median()
        ax.axhline(median_val, color="orange", linestyle="--", linewidth=1,label=f"Median: {median_val:.2f}")
        
        ax.set_title(f'{col}', fontsize=12, fontweight='bold')
        ax.set_ylabel(col)
        ax.set_xlabel("")
        ax.legend(fontsize=12)
        ax.grid(True, alpha=0.3, axis='y')

        # IQR Outlier calculation
        Q1 = np.percentile(data, 25)
        Q3 = np.percentile(data, 75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = data[(data < lower_bound) | (data > upper_bound)]
        outlier_pct = len(outliers) / len(data) * 100

        ax.text(
            0.02, 0.98,
            f'Outliers: {len(outliers)} ({outlier_pct:.1f}%)',
            transform=ax.transAxes,
            fontsize=12,
            verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)
        )

    for idx in range(len(numerical_cols), len(axes)):
        fig.delaxes(axes[idx])

    plt.suptitle('Box Plots of Numerical Variables\n')
    plt.tight_layout()
    plt.savefig('../visualizations/Numerical_box_plots', dpi=300, bbox_inches='tight')
    plt.show()





if numerical_cols:
    outlier_summary = []
    for col in numerical_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        outlier_pct = len(outliers) / len(df) * 100
        
        outlier_summary.append({
            'Column': col,
            'Outliers': len(outliers),
            'Percentage': f'{outlier_pct:.2f}%',
            'Lower_Bound': f'{lower_bound:.2f}',
            'Upper_Bound': f'{upper_bound:.2f}'
        })
    
    outlier_df = pd.DataFrame(outlier_summary)
    print(outlier_df.to_string(index=False))





# original_size = len(df)

# # 1. Remove unrealistic ages
# df = df[(df['Age'] >= 10) & (df['Age'] <= 90)].copy()
# print(f"‚úì Removed {original_size - len(df):,} rows with Age out of range of [10, 90]")

# # 2. Remove excessive return rates
# before_return = len(df)
# df = df[df['Returns_Rate'] <= 80].copy()
# print(f"‚úì Removed {before_return - len(df):,} rows with Returns_Rate > 80%")

# print(f"\nFinal: {len(df):,} rows ({len(df)/original_size*100:.2f}% retained)")





df['Age'].min(), df['Age'].max()


original_cols = df.columns.to_list()
# 1. AGE SEGMENTATION
# Define age bins and labels
age_bins = [0, 10, 18, 30, 45, 60, 90, np.inf]
age_labels = ['Child (<10)', 'Teen (10-17)', 'Young Adult (18-29)', 
              'Adult (30-44)', 'Middle-Aged (45-59)', 'Senior (60-89)', 
              'Elderly (90+)']

df['Age_Category'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)

# Statistics
print("\nüìä Age Category Distribution:")
age_dist = df['Age_Category'].value_counts().sort_index()
for category, count in age_dist.items():
    pct = count / len(df) * 100
    print(f"  ‚Ä¢ {category:25s}: {count:6,} ({pct:5.2f}%)")

categorical_cols.append('Age_Category')


# 2. RETURNS RATE SEGMENTATION
# Define return rate bins and labels
return_bins = [0, 5, 20, 40, 80, 100]
return_labels = ['Keeper', 'Normal', 'Frequent Returner', 
                'High Risk', 'Abusive']

df['Returner_Type'] = pd.cut(df['Returns_Rate'], bins=return_bins, labels=return_labels, right=False)

# Statistics

print("üìä Returner Type Distribution:")
for category, count in df['Returner_Type'].value_counts().items():
    pct = count / len(df) * 100
    avg_return = df[df['Returner_Type'] == category]['Returns_Rate'].mean()
    print(f"  ‚Ä¢ {category:20s}: {count:6,} ({pct:5.2f}%) | Avg: {avg_return:.2f}%")

categorical_cols.append('Returner_Type')


# 3. AVERAGE ORDER VALUE SEGMENTATION (VIP STATUS)
# Calculate percentiles for AOV
q25 = df['Average_Order_Value'].quantile(0.25)
q50 = df['Average_Order_Value'].quantile(0.50)
q75 = df['Average_Order_Value'].quantile(0.75)
q90 = df['Average_Order_Value'].quantile(0.90)
q95 = df['Average_Order_Value'].quantile(0.95)

print(f"\nüìä Average Order Value Percentiles:")
print(f"  ‚Ä¢ 25th percentile: ${q25:.2f}")
print(f"  ‚Ä¢ 50th percentile: ${q50:.2f}")
print(f"  ‚Ä¢ 75th percentile: ${q75:.2f}")
print(f"  ‚Ä¢ 90th percentile: ${q90:.2f}")
print(f"  ‚Ä¢ 95th percentile: ${q95:.2f}")

# Create spending tiers
def classify_spender(aov):
    if aov < q25:
        return 'Budget Shopper'
    elif aov < q50:
        return 'Value Shopper'
    elif aov < q75:
        return 'Regular Shopper'
    elif aov < q90:
        return 'Premium Shopper'
    elif aov < q95:
        return 'Luxury Shopper'
    else:
        return 'VIP'

df['Spender_Type'] = df['Average_Order_Value'].apply(classify_spender)

# Statistics
print("\nüìä Spender Type Distribution:")
spender_dist = df['Spender_Type'].value_counts()
for category in ['Budget Shopper', 'Value Shopper', 'Regular Shopper', 
                'Premium Shopper', 'Luxury Shopper', 'VIP']:
    if category in spender_dist.index:
        count = spender_dist[category]
        pct = count / len(df) * 100
        avg_aov = df[df['Spender_Type'] == category]['Average_Order_Value'].mean()
        avg_ltv = df[df['Spender_Type'] == category]['Lifetime_Value'].mean()
        print(f"  ‚Ä¢ {category:20s}: {count:6,} ({pct:5.2f}%) | Avg AOV: ${avg_aov:7.2f} | Avg LTV: ${avg_ltv:8.2f}")

categorical_cols.append('Spender_Type')


# 4. TOTAL PURCHASES SEGMENTATION (LOYALTY)
# Calculate percentiles
p25 = df['Total_Purchases'].quantile(0.25)
p50 = df['Total_Purchases'].quantile(0.50)
p75 = df['Total_Purchases'].quantile(0.75)
p90 = df['Total_Purchases'].quantile(0.90)

print(f"\nüìä Total Purchases Percentiles:")
print(f"  ‚Ä¢ 25th percentile: {p25:.0f} orders")
print(f"  ‚Ä¢ 50th percentile: {p50:.0f} orders")
print(f"  ‚Ä¢ 75th percentile: {p75:.0f} orders")
print(f"  ‚Ä¢ 90th percentile: {p90:.0f} orders")

# Create loyalty tiers
def classify_loyalty(purchases):
    if purchases < 0:
        return 'Negative'
    if purchases < p25:
        return 'Occasional'
    elif purchases < p50:
        return 'Regular'
    elif purchases < p75:
        return 'Frequent'
    elif purchases < p90:
        return 'Loyal'
    else:
        return 'Power User'

df['Loyalty_Segment'] = df['Total_Purchases'].apply(classify_loyalty)

# Statistics
print("\nüìä Loyalty Segment Distribution:")
loyalty_dist = df['Loyalty_Segment'].value_counts()
for category in ['Negative', 'Occasional', 'Regular', 'Frequent', 'Loyal', 'Power User']:
    if category in loyalty_dist.index:
        count = loyalty_dist[category]
        pct = count / len(df) * 100
        avg_purchases = df[df['Loyalty_Segment'] == category]['Total_Purchases'].mean()
        avg_ltv = df[df['Loyalty_Segment'] == category]['Lifetime_Value'].mean()
        print(f"  ‚Ä¢ {category:15s}: {count:6,} ({pct:5.2f}%) | Avg Orders: {avg_purchases:5.1f} | Avg LTV: ${avg_ltv:8.2f}")

categorical_cols.append('Loyalty_Segment')


# 5. LIFETIME VALUE SEGMENTATION
# Calculate percentiles
ltv_p25 = df['Lifetime_Value'].quantile(0.25)
ltv_p50 = df['Lifetime_Value'].quantile(0.50)
ltv_p75 = df['Lifetime_Value'].quantile(0.75)
ltv_p90 = df['Lifetime_Value'].quantile(0.90)
ltv_p95 = df['Lifetime_Value'].quantile(0.95)

print(f"\nüìä Lifetime Value Percentiles:")
print(f"  ‚Ä¢ 25th percentile: ${ltv_p25:.2f}")
print(f"  ‚Ä¢ 50th percentile: ${ltv_p50:.2f}")
print(f"  ‚Ä¢ 75th percentile: ${ltv_p75:.2f}")
print(f"  ‚Ä¢ 90th percentile: ${ltv_p90:.2f}")
print(f"  ‚Ä¢ 95th percentile: ${ltv_p95:.2f}")

# Create value tiers
def classify_value(ltv):
    if ltv < ltv_p25:
        return 'Low Value'
    elif ltv < ltv_p50:
        return 'Medium Value'
    elif ltv < ltv_p75:
        return 'High Value'
    elif ltv < ltv_p90:
        return 'Very High Value'
    else:
        return 'Premium Value'

df['Value_Segment'] = df['Lifetime_Value'].apply(classify_value)

# Statistics
print("\nüìä Value Segment Distribution:")
value_dist = df['Value_Segment'].value_counts()
for category in ['Low Value', 'Medium Value', 'High Value', 'Very High Value', 'Premium Value']:
    if category in value_dist.index:
        count = value_dist[category]
        pct = count / len(df) * 100
        avg_ltv = df[df['Value_Segment'] == category]['Lifetime_Value'].mean()
        print(f"  ‚Ä¢ {category:20s}: {count:6,} ({pct:5.2f}%) | Avg LTV: ${avg_ltv:9.2f}")

categorical_cols.append('Value_Segment')





print(categorical_cols)





if categorical_cols:
    print(f"Original 5 Categorical Variables' Value Distribution:")
    for col in categorical_cols[:5]: # just show the original 5
        print(f"{'='*60}")
        value_counts = df[col].value_counts()
        print(value_counts.head(10))
        print(f"Total Unique Values: {df[col].nunique()}")
        if df[col].nunique() > 10:
            print(f"(Showing top 10 only)")


# Categorize variables by unique count
n = 5
pie_chart_vars = [col for col in categorical_cols if df[col].nunique() <= n]
bar_chart_vars = [col for col in categorical_cols if df[col].nunique() > n]
print(f"\nüìä Visualization Strategy:")
print(f"  ‚Ä¢ Pie charts (‚â§{n} unique): {len(pie_chart_vars)} variables")
print(f"    {pie_chart_vars}")
print(f"  ‚Ä¢ Horizontal bar charts (>{n} unique): {len(bar_chart_vars)} variables")
print(f"    {bar_chart_vars}")





if pie_chart_vars:
    n_cols = 3
    n_rows = (len(pie_chart_vars) + n_cols - 1) // n_cols
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6*n_rows))
    
    # Handle single subplot case
    if len(pie_chart_vars) == 1:
        axes = [axes]
    else:
        axes = axes.flatten()
    
    # Color palettes
    color_palettes = {
        2: ['#3498DB', '#E74C3C'],
        3: ['#3498DB', '#E74C3C', '#95A5A6'],
        4: ['#3498DB', '#E74C3C', '#2ECC71', '#F39C12'],
        5: ['#3498DB', '#E74C3C', '#2ECC71', '#F39C12', '#9B59B6'],
        6: ['#3498DB', '#E74C3C', '#2ECC71', '#F39C12', '#9B59B6', '#1ABC9C']
    }
    
    for idx, col in enumerate(pie_chart_vars):
        ax = axes[idx]
        
        value_counts = df[col].value_counts()
        n_categories = len(value_counts)
        colors = color_palettes.get(n_categories, sns.color_palette("husl", n_categories))
        
        # Create pie chart
        wedges, texts, autotexts = ax.pie(
            value_counts.values,
            labels=value_counts.index,
            autopct='%1.1f%%',
            startangle=90,
            colors=colors,
            explode=[0.05] * len(value_counts),
            textprops={'fontsize': 12, 'fontweight': 'bold'}
        )
        
        # Enhance percentage text
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontsize(14)
            autotext.set_fontweight('bold')
        
        ax.set_title(f'{col}', 
                    fontsize=12, fontweight='bold', pad=15)
    
    # Remove empty subplots
    for idx in range(len(pie_chart_vars), len(axes)):
        fig.delaxes(axes[idx])
    
    plt.suptitle('Pie Chart for Categorical Variables with <=5 Classes\n\n')
    plt.tight_layout()
    plt.savefig('../visualizations/categorical_pie_charts.png', dpi=300, bbox_inches='tight')
    plt.show()





if bar_chart_vars:
    for col in bar_chart_vars:
        # Determine how many categories to show
        n_unique = df[col].nunique()
        show_top_n = min(15, n_unique)  # Show max 15 categories
        
        plt.figure(figsize=(12, max(6, show_top_n * 0.4)))
        
        value_counts = df[col].value_counts().head(show_top_n)
        
        # Create horizontal bar chart
        y_pos = np.arange(len(value_counts))
        plt.barh(y_pos, value_counts.values, color='steelblue', 
                edgecolor='black', alpha=0.7)
        
        # Set y-axis labels
        plt.yticks(y_pos, value_counts.index, fontsize=10)
        
        # Add count and percentage labels
        total = len(df)
        for i, v in enumerate(value_counts.values):
            pct = v / total * 100
            plt.text(v + max(value_counts.values)*0.01, i, 
                    f'{v:,} ({pct:.1f}%)', 
                    va='center', fontsize=9, fontweight='bold')
        
        plt.xlabel('Count', fontsize=11, fontweight='bold')
        plt.ylabel(col, fontsize=11, fontweight='bold')
        plt.title(f'Distribution of {col}\n(Showing Top {show_top_n} of {n_unique} categories)', 
                 fontsize=13, fontweight='bold', pad=15)
        plt.grid(True, alpha=0.3, axis='x')
        
        plt.tight_layout()
        plt.savefig(f'../visualizations/barh_{col.lower()}.png', dpi=300, bbox_inches='tight')
        plt.show()





original_categorical = list(set(categorical_cols) - (set(df.columns) - set(original_cols)))
original_numerical = list(set(original_cols) - set(original_categorical))
print("original_cols:\n ", original_cols)
print("\noriginal_categorical:\n ", original_categorical)
print("\noriginal_numerical:\n ", original_numerical)





from scipy.stats import pearsonr, spearmanr, chi2_contingency, f_oneway
from scipy.stats.contingency import association

if len(original_numerical) >= 2:
    numerical_corr = df[original_numerical].corr(method='pearson')
    
    print(f"\nCalculated {len(original_numerical)} √ó {len(original_numerical)} correlation matrix")
    
    # Find strong correlations
    strong_corr = []
    for i in range(len(numerical_corr.columns)):
        for j in range(i+1, len(numerical_corr.columns)):
            corr_val = numerical_corr.iloc[i, j]
            if abs(corr_val) > 0.5:  # Moderate to strong
                strong_corr.append({
                    'Feature_1': numerical_corr.columns[i],
                    'Feature_2': numerical_corr.columns[j],
                    'Pearson_r': corr_val,
                    'Strength': 'Strong' if abs(corr_val) > 0.7 else 'Moderate'
                })
    
    if strong_corr:
        corr_df = pd.DataFrame(strong_corr).sort_values('Pearson_r', key=abs, ascending=False)
        print("\nModerate to Strong Correlations (|r| > 0.5):")
        print(corr_df.to_string(index=False))
    else:
        print("\n‚úÖ No strong numerical correlations found (all |r| < 0.5)")
    


# Visualize
plt.figure(figsize=(16, 14))
mask = np.triu(np.ones_like(numerical_corr, dtype=bool))
sns.heatmap(numerical_corr, mask=mask, annot=True, fmt='.2f',
            cmap='coolwarm', center=0, vmin=-1, vmax=1,
            square=True, linewidths=1, cbar_kws={'label': 'Pearson r'})
plt.title('Numerical Features - Pearson Correlation', fontsize=15, fontweight='bold')
plt.tight_layout()
plt.savefig('../visualizations/correlation_numerical_pearson.png', dpi=300, bbox_inches='tight')
plt.show()








def cramers_v(x, y):
    """Calculate Cram√©r's V statistic for categorical-categorical association"""
    contingency_table = pd.crosstab(x, y)
    chi2 = chi2_contingency(contingency_table)[0]
    n = contingency_table.sum().sum()
    min_dim = min(contingency_table.shape) - 1
    return np.sqrt(chi2 / (n * min_dim))

# Define meaningful categorical features (original + independent derived)
categorical_for_cramers = [
    # Original features
    'City',
    'Gender',
    'Churned',
    'Signup_Quarter',
    
    # Independent derived features
    'Age_Category',      # From Age
    'Returner_Type',     # From Returns_Rate
    'Loyalty_Segment',   # From Total_Purchases
    'Spender_Type'       # From Average_Order_Value
    
    # Excluded: Value_Segment (to avoid LTV = AOV √ó Purchases circular dependency)
]

# Filter to existing columns
categorical_for_cramers = [col for col in categorical_for_cramers if col in df.columns]

print(f"\nUsing {len(categorical_for_cramers)} categorical features:")
print(f"  ‚Ä¢ Original: Gender, Churned, Signup_Quarter")
print(f"  ‚Ä¢ Derived: Age_Category, Returner_Type, Loyalty_Segment, Spender_Type")
print(f"  ‚Ä¢ Excluded: Value_Segment (to avoid circular dependency with Spender + Loyalty)")

if len(categorical_for_cramers) >= 2:
    # Calculate Cram√©r's V for all pairs
    cramers_matrix = pd.DataFrame(index=categorical_for_cramers, 
                                  columns=categorical_for_cramers,
                                  dtype=float)
    
    for cat1 in categorical_for_cramers:
        for cat2 in categorical_for_cramers:
            if cat1 == cat2:
                cramers_matrix.loc[cat1, cat2] = 1.0
            else:
                cramers_matrix.loc[cat1, cat2] = cramers_v(df[cat1], df[cat2])
    
    print(f"\nCalculated {len(categorical_for_cramers)} √ó {len(categorical_for_cramers)} Cram√©r's V matrix")
    
    # Find strong associations
    strong_assoc = []
    for i, cat1 in enumerate(categorical_for_cramers):
        for j, cat2 in enumerate(categorical_for_cramers):
            if i < j:
                v_val = cramers_matrix.loc[cat1, cat2]
                if v_val > 0.3:  # Moderate to strong
                    strong_assoc.append({
                        'Feature_1': cat1,
                        'Feature_2': cat2,
                        'Cramers_V': v_val,
                        'Strength': 'Strong' if v_val > 0.5 else 'Moderate'
                    })
    
    if strong_assoc:
        assoc_df = pd.DataFrame(strong_assoc).sort_values('Cramers_V', ascending=False)
        print("\nModerate to Strong Associations (V > 0.3):")
        print(assoc_df.to_string(index=False))
    else:
        print("\n‚úÖ No strong categorical associations found (all V < 0.3)")
    
    # Visualize
    plt.figure(figsize=(12, 10))
    mask = np.triu(np.ones_like(cramers_matrix, dtype=bool))
    sns.heatmap(cramers_matrix, 
                mask=mask, 
                annot=True, 
                fmt='.2f',
                cmap='YlOrRd', 
                vmin=0, 
                vmax=1, 
                square=True, 
                linewidths=1,
                cbar_kws={'label': "Cram√©r's V"},
                linecolor='white')
    
    plt.title("Categorical Features Association (Cram√©r's V)\nOriginal + Meaningful Derived Features", 
              fontsize=14, fontweight='bold', pad=20)
    plt.xlabel('Categorical Features', fontsize=11, fontweight='bold')
    plt.ylabel('Categorical Features', fontsize=11, fontweight='bold')
    plt.xticks(rotation=45, ha='right', fontsize=10)
    plt.yticks(rotation=0, fontsize=10)
    
    plt.tight_layout()
    plt.savefig('../visualizations/correlation_categorical_cramers.png', dpi=300, bbox_inches='tight')
    plt.show()








def eta_squared(categorical, numerical):
    """Calculate eta-squared (effect size) for categorical-numerical relationship"""
    categories = df[categorical].unique()
    groups = [df[df[categorical] == cat][numerical].dropna() for cat in categories]
    
    # Remove empty groups
    groups = [g for g in groups if len(g) > 0]
    
    if len(groups) < 2:
        return 0, 1  # Not enough groups
    
    # Perform ANOVA
    result = f_oneway(*groups)
    f_stat = result.statistic
    p_value = result.pvalue
    
    # Calculate eta-squared
    grand_mean = df[numerical].mean()
    ss_between = sum(len(g) * (g.mean() - grand_mean)**2 for g in groups)
    ss_total = sum((df[numerical] - grand_mean)**2)
    
    eta_sq = ss_between / ss_total if ss_total > 0 else 0
    
    return eta_sq, p_value

# Calculate for all categorical-numerical pairs
cat_num_relationships = []

for cat_col in original_categorical:
    for num_col in original_numerical:
        eta_sq, p_value = eta_squared(cat_col, num_col)
        
        if eta_sq > 0.01:  # Only show meaningful relationships
            cat_num_relationships.append({
                'Categorical': cat_col,
                'Numerical': num_col,
                'Eta_Squared': eta_sq,
                'P_Value': p_value,
                'Significant': 'Yes ‚úì' if p_value < 0.05 else 'No',
                'Effect_Size': 'Large' if eta_sq > 0.14 else 'Medium' if eta_sq > 0.06 else 'Small'
            })

if cat_num_relationships:
    cat_num_df = pd.DataFrame(cat_num_relationships).sort_values('Eta_Squared', ascending=False)
    
    print(f"\nFound {len(cat_num_df)} categorical-numerical relationships")
    print("\nTop 20 Relationships by Effect Size:")
    print(cat_num_df.head(20).to_string(index=False))

else:
    print("\n‚ö†Ô∏è  No meaningful categorical-numerical relationships found")



if cat_num_relationships:
    # Create eta-squared matrix for heatmap
    eta_matrix = pd.DataFrame(index=original_categorical, columns=original_numerical, dtype=float)
    
    # Fill matrix with eta-squared values
    for cat_col in original_categorical:
        for num_col in original_numerical:
            result = eta_squared(cat_col, num_col)
            eta_sq = result[0] if isinstance(result, tuple) else result
            eta_matrix.loc[cat_col, num_col] = eta_sq
    
    # Create figure with two subplots side by side
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
    
    # ========================================================================
    # LEFT: Heatmap (Transposed - Vertical, Filtered & Sorted)
    # ========================================================================
    
    # Transpose the matrix (swap rows and columns)
    eta_matrix_transposed = eta_matrix.T
    
    # Filter: Remove columns (categorical features) where all values < 0.01
    cols_to_keep = []
    for col in eta_matrix_transposed.columns:
        if (eta_matrix_transposed[col] >= 0.01).any():  # At least one value >= 0.01
            cols_to_keep.append(col)
    
    eta_matrix_filtered = eta_matrix_transposed[cols_to_keep]
    
    # Sort by Churned column (if it exists)
    if 'Churned' in eta_matrix_filtered.columns:
        eta_matrix_sorted = eta_matrix_filtered.sort_values(by='Churned', ascending=True)
    else:
        eta_matrix_sorted = eta_matrix_filtered
    
    sns.heatmap(eta_matrix_sorted, 
                annot=True, 
                fmt='.3f',
                cmap='YlOrRd',
                vmin=0, 
                vmax=0.15,
                cbar_kws={'label': 'Eta-squared'},
                linewidths=0.5,
                linecolor='white',
                ax=ax1)
    
    ax1.set_title('Heatmap: Categorical ‚Üî Numerical\n(Eta-squared ‚â• 0.01, Sorted by Churned)', 
                  fontsize=13, fontweight='bold', pad=15)
    ax1.set_xlabel('Categorical Features', fontsize=11, fontweight='bold')
    ax1.set_ylabel('Numerical Features', fontsize=11, fontweight='bold')
    ax1.tick_params(axis='x', rotation=45, labelsize=9)
    ax1.tick_params(axis='y', rotation=0, labelsize=9)
    
    # ========================================================================
    # RIGHT: Top 15 Horizontal Bar Chart (Matching Colors)
    # ========================================================================
    
    # Get top 15 relationships
    top_relationships = cat_num_df.head(15).copy()
    
    # Create labels
    top_relationships['Pair'] = (top_relationships['Categorical'] + ' ‚Üí ' + 
                                top_relationships['Numerical'])
    
    # Color mapping based on eta-squared value (matching YlOrRd)
    from matplotlib.colors import LinearSegmentedColormap
    import matplotlib.cm as cm
    
    # Use same colormap as heatmap
    cmap = cm.get_cmap('YlOrRd')
    norm = plt.Normalize(vmin=0, vmax=0.15)  # Same scale as heatmap
    
    # Map eta-squared values to colors
    colors = [cmap(norm(val)) for val in top_relationships['Eta_Squared']]
    
    ax2.barh(range(len(top_relationships)), top_relationships['Eta_Squared'],
            color=colors, edgecolor='black', alpha=0.9)
    
    ax2.set_yticks(range(len(top_relationships)))
    ax2.set_yticklabels(top_relationships['Pair'], fontsize=9)
    ax2.set_xlabel('Eta-squared (Effect Size)', fontsize=11, fontweight='bold')
    ax2.set_title('Top 15 Relationships\n(Ranked by Effect Size)', 
                  fontsize=13, fontweight='bold', pad=15)
    ax2.grid(True, alpha=0.3, axis='x')
    
    # Add effect size thresholds
    ax2.axvline(x=0.01, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)
    ax2.axvline(x=0.06, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)
    ax2.axvline(x=0.14, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)
    
    # Add value labels
    for i, v in enumerate(top_relationships['Eta_Squared']):
        ax2.text(v + 0.002, i, f'{v:.3f}', va='center', fontsize=8, fontweight='bold')
    
    # Add text annotations for thresholds
    ax2.text(0.01, -0.7, 'Small', fontsize=8, ha='center', style='italic')
    ax2.text(0.06, -0.7, 'Medium', fontsize=8, ha='center', style='italic')
    ax2.text(0.14, -0.7, 'Large', fontsize=8, ha='center', style='italic')
    
    # Overall title
    fig.suptitle('Categorical ‚Üî Numerical Relationships Analysis', 
                fontsize=16, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    plt.savefig('../visualizations/categorical_numerical_combined.png', dpi=300, bbox_inches='tight')
    plt.show()

else:
    print("\n‚ö†Ô∏è  No visualizations created (no meaningful relationships found)")








# COMPREHENSIVE CORRELATION SUMMARY
print(f"  ‚Ä¢ Numerical ‚Üî Numerical (Pearson): {len(original_numerical)*(len(original_numerical)-1)//2} pairs")
if strong_corr:
    print(f"    ‚îî‚îÄ Found {len(strong_corr)} strong correlations (|r| > 0.5)")

print(f"\n  ‚Ä¢ Categorical ‚Üî Categorical (Cram√©r's V): {len(original_categorical)*(len(original_categorical)-1)//2} pairs")
if strong_assoc:
    print(f"    ‚îî‚îÄ Found {len(strong_assoc)} strong associations (V > 0.3)")

print(f"\n  ‚Ä¢ Categorical ‚Üî Numerical (ANOVA): {len(original_categorical) * len(original_numerical)} pairs")
if cat_num_relationships:
    sig_relationships = sum(1 for r in cat_num_relationships if r['Significant'] == 'Yes ‚úì')
    print(f"    ‚îî‚îÄ Found {sig_relationships} significant relationships (p < 0.05)")


df.to_csv('../data/processed/cleaned_with_more_cat.csv')




















df = pd.read_csv('../data/processed/cleaned_with_more_cat.csv')
df = df.drop(columns=["Unnamed: 0"])
df.head(1)


# Configure unified Plotly theme and color palette
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Define unified color palette
COLOR_PALETTE = {
    'primary': '#3498DB',      # Blue
    'secondary': '#E74C3C',    # Red
    'success': '#2ECC71',      # Green
    'warning': '#F39C12',      # Orange
    'info': '#9B59B6',         # Purple
    'churned': '#E74C3C',      # Red for churned
    'active': '#2ECC71',       # Green for active
    'vip': '#F39C12',          # Gold for VIP
    'standard': '#3498DB'      # Blue for standard
}

# Define consistent template
PLOTLY_TEMPLATE = 'plotly_white'








# Data Aggregation & Sorting
# Group data to find high-value segments
revenue_pivot = df.groupby(['Age_Category', 'Spender_Type']).agg({
    'Lifetime_Value': 'mean',
    'Churned': 'mean',
    'Customer_Service_Calls': 'count'
}).reset_index()

revenue_pivot.columns = ['Age_Category', 'Spender_Type', 'Avg_LTV', 'Churn_Rate', 'Customer_Count']

# Sorting
# Age: Oldest to youngest (for better 3D view)
# age_order = ['Child (<10)', 'Teen (10-17)', 'Young Adult (18-29)', 'Adult (30-44)', 
#              'Middle-Aged (45-59)', 'Senior (60+)', 'Elderly (90+)']
age_order = ['Elderly (90+)', 'Senior (60+)', 'Middle-Aged (45-59)', 'Adult (30-44)', 
            'Young Adult (18-29)', 'Teen (10-17)', 'Child (<10)']

age_rank = [age for age in age_order if age in revenue_pivot['Age_Category'].unique()]

spender_rank = revenue_pivot.groupby('Spender_Type')['Avg_LTV'].mean().sort_values(ascending=False).index.tolist()

# Calculate spender type AOV thresholds for annotation
spender_thresholds = df.groupby('Spender_Type')['Average_Order_Value'].agg(['min', 'max'])

# 3D Bar
fig = go.Figure()

width = 0.5 

colorscale = px.colors.sequential.Viridis

for age in age_rank:
    for spender in spender_rank:
        subset = revenue_pivot[(revenue_pivot['Age_Category'] == age) & 
                               (revenue_pivot['Spender_Type'] == spender)]
        
        if not subset.empty:
            row = subset.iloc[0]
            val = row['Avg_LTV']
            churn = row['Churn_Rate']
            
            x_pos = age_rank.index(age)
            y_pos = spender_rank.index(spender)
            
            # Color
            color_idx = int(churn * (len(colorscale) - 1))
            chosen_color = colorscale[color_idx]
            color = f'rgba({150 + (105 * churn)}, {200 * (1 - churn)}, 100, 0.85)'

            # Define 8 vertices for the 3D cube
            x_v = [x_pos, x_pos, x_pos+width, x_pos+width, x_pos, x_pos, x_pos+width, x_pos+width]
            y_v = [y_pos, y_pos+width, y_pos+width, y_pos, y_pos, y_pos+width, y_pos+width, y_pos]
            z_v = [0, 0, 0, 0, val, val, val, val]

            # Define 12 triangles for 6 faces
            fig.add_trace(go.Mesh3d(
                x=x_v, y=y_v, z=z_v,
                i=[7, 0, 0, 0, 4, 4, 6, 6, 4, 0, 3, 2],
                j=[3, 4, 1, 2, 5, 6, 5, 2, 0, 1, 6, 3],
                k=[0, 7, 2, 3, 6, 7, 1, 1, 5, 5, 7, 6],
                color=chosen_color,
                flatshading=True,
                name=f"{age}-{spender}",
                hovertemplate=(
                    f"<b>{age}</b> | {spender}<br>"
                    f"Avg LTV: ${val:,.2f}<br>"
                    f"Churn Risk: {churn:.1%}<br>"
                    f"Count: {row['Customer_Count']}<extra></extra>"
                ),
                showlegend=False
            ))

# Layout with Annotations
fig.update_layout(
    title={
        'text': "Lifetime Value by Segment & Age"
        , 'y': 0.98, 'x': 0.35
        , 'xanchor': 'center', 'yanchor': 'top'
    },
    scene=dict(
        xaxis=dict(
            title='Age Group', 
            tickvals=list(range(len(age_rank))), 
            ticktext=age_rank,
            tickfont=dict(size=10)
        ),
        yaxis=dict(
            title='Spender Type', 
            tickvals=list(range(len(spender_rank))), 
            ticktext=["Budget", "Value", "Regular", "Premium", "Luxury", "VIP"],
            tickfont=dict(size=10)
        ),
        zaxis=dict(title='Average LTV ($)'),
        camera=dict(eye=dict(x=2.0, y=1.2, z=1.0)),
        aspectmode='manual',
        aspectratio=dict(x=1.2, y=1.2, z=0.7) 
    ),
    margin=dict(l=50, r=200, b=150, t=0),
    height=700,
    # NEW: Add annotations
    annotations=[
        # Color legend (top right)
        dict(
            text='<b>Color Gradient</b><br>' +
                 'Purple-Blue = Low Churn<br>' +
                 'Green-Yellow = High Churn',
            xref="paper",
            yref="paper",
            x=0.80,
            y=0.93,
            xanchor="right",
            yanchor="top",
            showarrow=False,
            bgcolor="rgba(255, 255, 255, 0.9)",
            bordercolor="gray",
            borderwidth=1.5,
            borderpad=10,
            font=dict(size=10),
            align="left"
        ),
        # Spender Type definitions (bottom, 2 rows √ó 3 columns)
        dict(
            text='<b>Spender Type Definitions (Based on Average Order Value)</b><br>' +
                 f'<b>VIP:</b> ${spender_thresholds.loc["VIP", "min"]:.0f}+  |  ' +
                 f'<b>Luxury Shopper:</b> ${spender_thresholds.loc["Luxury Shopper", "min"]:.0f}-${spender_thresholds.loc["Luxury Shopper", "max"]:.0f}  |  ' +
                 f'<b>Premium Shopper:</b> ${spender_thresholds.loc["Premium Shopper", "min"]:.0f}-${spender_thresholds.loc["Premium Shopper", "max"]:.0f}<br>' +
                 f'<b>Regular Shopper:</b> ${spender_thresholds.loc["Regular Shopper", "min"]:.0f}-${spender_thresholds.loc["Regular Shopper", "max"]:.0f}  |  ' +
                 f'<b>Value Shopper:</b> ${spender_thresholds.loc["Value Shopper", "min"]:.0f}-${spender_thresholds.loc["Value Shopper", "max"]:.0f}  |  ' +
                 f'<b>Budget Shopper:</b> < ${spender_thresholds.loc["Budget Shopper", "max"]:.0f}',
            xref="paper",
            yref="paper",
            x=0.5,
            y=-0.08,
            xanchor="center",
            yanchor="top",
            showarrow=False,
            bgcolor="rgba(255, 255, 255, 0.95)",
            # bordercolor="gray",
            # borderwidth=1.5,
            # borderpad=8,
            font=dict(size=10),
            align="center"
        )
    ]
)

fig.show()
fig.write_html('../visualizations/viz1_3d_revenue_contribution.html')








# Prepare data
bubble_df = df[[
    'Social_Media_Engagement_Score',
    'Lifetime_Value',
    'Wishlist_Items',
    'Age_Category'
]].dropna().copy()
# Stratified sampling - keep proportions
from sklearn.model_selection import train_test_split

SAMPLE_SIZE = 5000

if len(bubble_df) > SAMPLE_SIZE:
    bubble_df_plot, _ = train_test_split(
        bubble_df, 
        train_size=SAMPLE_SIZE, 
        stratify=bubble_df['Age_Category'],
        random_state=42
    )
    print(f"Stratified sample: {SAMPLE_SIZE:,} records (maintains age distribution)")
else:
    bubble_df_plot = bubble_df

# Create figure
fig = go.Figure()

# Age categories and colors
# Age categories in ORDER (youngest to oldest)
age_order = ['Child (<10)', 'Teen (10-17)', 'Young Adult (18-29)','Adult (30-44)','Middle-Aged (45-59)','Senior (60+)','Elderly (90+)']

# Filter to existing categories and maintain order
age_categories = [age for age in age_order if age in bubble_df_plot['Age_Category'].unique()]

age_colors = {
    'Child (<10)': '#E91E63',
    'Teen (10-17)': '#CE93D8',
    'Young Adult (18-29)': '#3498DB',
    'Adult (30-44)': '#2ECC71',
    'Middle-Aged (45-59)': '#F39C12',
    'Senior (60+)': '#E74C3C',
    'Elderly (90+)': '#9E9E9E'
}

# Add trace for each age category
for age_cat in age_categories:
    age_data = bubble_df_plot[bubble_df_plot['Age_Category'] == age_cat]
    
    fig.add_trace(go.Scatter(
        x=age_data['Social_Media_Engagement_Score'],
        y=age_data['Lifetime_Value'],
        mode='markers',
        name=age_cat,
        marker=dict(
            size=age_data['Wishlist_Items'] * 2,  # Scale for visibility
            color=age_colors.get(age_cat, '#3498DB'),
            opacity=0.6,
            line=dict(width=1, color='white'),
            sizemode='diameter'
        ),
        text=age_data.apply(lambda row:
            f"Age: {row['Age_Category']}<br>" +
            f"Social Score: {row['Social_Media_Engagement_Score']:.1f}<br>" +
            f"LTV: ${row['Lifetime_Value']:.2f}<br>" +
            f"Wishlist Items: {row['Wishlist_Items']:.0f}",
            axis=1
        ),
        hovertemplate='%{text}<extra></extra>',
        visible=True
    ))

# Add trendline
from scipy import stats
slope, intercept, r_value, p_value, std_err = stats.linregress(
    bubble_df_plot['Social_Media_Engagement_Score'], 
    bubble_df_plot['Lifetime_Value']
)
x_trend = np.linspace(bubble_df_plot['Social_Media_Engagement_Score'].min(), 
                     bubble_df_plot['Social_Media_Engagement_Score'].max(), 100)
y_trend = slope * x_trend + intercept

fig.add_trace(go.Scattergl(
    x=x_trend,
    y=y_trend,
    mode='lines',
    name='Trend Line',
    line=dict(color='red', width=3, dash='dash'),
    hovertemplate=f'Trendline (r={r_value:.3f})<extra></extra>',
    visible=True
))

# Update layout with checkboxes for age categories
fig.update_layout(
    updatemenus=[
        dict(
            buttons=[
                # Select All button
                dict(
                    label="Select All",
                    method="update",
                    args=[{"visible": [True] * len(fig.data)}]
                ),
                # Deselect All button
                dict(
                    label="Deselect All",
                    method="update",
                    args=[{"visible": [False] * (len(fig.data) - 1) + [True]}]  # Keep trendline
                )
            ],
            type="buttons",
            direction="down",
            x=0.01,
            y=1.01,
            xanchor="left",
            yanchor="top",
            bgcolor="white",
            bordercolor="gray",
            borderwidth=1.5,
            font=dict(size=10),
            pad={"r": 10, "t": 10}
        )
    ],
    # Enable legend as interactive checkboxes
    showlegend=True,
    legend=dict(
        title_text='<b>Age Category</b><br>(Click to toggle)',
        orientation="v",
        yanchor="top",
        y=0.99,
        xanchor="right",
        x=1.10,
        bgcolor="rgba(255, 255, 255, 0.9)",
        bordercolor="gray",
        borderwidth=1.5,
        font=dict(size=10),
        itemclick="toggle",  # ‚Üê Enable click to toggle
        itemdoubleclick="toggleothers"  # ‚Üê Double-click to show only this one
    ),
    # Bubble size annotation
    annotations=[
        dict(
            text='<b>Bubble Size</b><br>' +
                 f'Small: < {bubble_df["Wishlist_Items"].quantile(0.33):.0f} items<br>' +
                 f'Medium: {bubble_df["Wishlist_Items"].quantile(0.33):.0f}-{bubble_df["Wishlist_Items"].quantile(0.67):.0f} items<br>' +
                 f'Large: > {bubble_df["Wishlist_Items"].quantile(0.67):.0f} items',
            xref="paper",
            yref="paper",
            x=0.15,
            y=0.99,  
            xanchor="left",
            yanchor="top",
            showarrow=False,
            bgcolor="rgba(255, 255, 255, 0.9)",
            bordercolor="gray",
            borderwidth=1.5,
            borderpad=8,
            font=dict(size=10),
            align="left"
        )
    ],
    title='Social Engagement ‚Üí Revenue Conversion by Age Group<br><sub>Click age categories to show/hide | Bubble Size = Wishlist Items</sub>',
    xaxis=dict(
        title='Social Media Engagement Score',
        gridcolor='lightgray',
        showgrid=True,
        zeroline=False
    ),
    yaxis=dict(
        title='Lifetime Value ($)',
        gridcolor='lightgray',
        showgrid=True,
        zeroline=False
    ),
    font=dict(size=12),
    height=700,
    template=PLOTLY_TEMPLATE,
    hovermode='closest'
)

fig.show()

# Save
fig.write_html('../visualizations/viz2_social_to_revenue_bubble.html')











# Prepare data with percentile transformation
plot_df = df[[
    'Session_Duration_Avg', 
    'Average_Order_Value', 
    'Total_Purchases',
    'Churned',
    'Lifetime_Value'
]].copy()

# Convert to percentile ranks (0-100)
plot_df['AOV_Percentile'] = plot_df['Average_Order_Value'].rank(pct=True) * 100
plot_df['Purchases_Percentile'] = plot_df['Total_Purchases'].rank(pct=True) * 100
plot_df['Session_Percentile'] = plot_df['Session_Duration_Avg'].rank(pct=True) * 100

# Create churn status label
plot_df['Churn_Status'] = plot_df['Churned'].map({0: 'Active', 1: 'Churned'})

# Separate data by churn status
active_df = plot_df[plot_df['Churned'] == 0]
churned_df = plot_df[plot_df['Churned'] == 1]


# Create figure
fig = go.Figure()

# Add trace for Active customers
fig.add_trace(go.Scatter3d(
    x=active_df['Session_Percentile'],
    y=active_df['AOV_Percentile'],
    z=active_df['Purchases_Percentile'],
    mode='markers',
    name='Active',
    marker=dict(
        size=active_df['Lifetime_Value'] / 200,
        color=COLOR_PALETTE['active'],
        opacity=0.6,
        line=dict(width=0.5, color='white'),
        sizemode='diameter'
    ),
    text=active_df.apply(lambda row: 
        f"Status: Active<br>" +
        f"Session: {row['Session_Duration_Avg']:.1f} min<br>" +
        f"Order Value: ${row['Average_Order_Value']:.2f}<br>" +
        f"Purchases: {row['Total_Purchases']:.0f}<br>" +
        f"LTV: ${row['Lifetime_Value']:.2f}",
        axis=1
    ),
    hovertemplate='%{text}<extra></extra>',
    visible=True
))

# Add trace for Churned customers
fig.add_trace(go.Scatter3d(
    x=churned_df['Session_Percentile'],
    y=churned_df['AOV_Percentile'],
    z=churned_df['Purchases_Percentile'],
    mode='markers',
    name='Churned',
    marker=dict(
        size=churned_df['Lifetime_Value'] / 200,
        color=COLOR_PALETTE['churned'],
        opacity=0.6,
        line=dict(width=0.5, color='white'),
        sizemode='diameter'
    ),
    text=churned_df.apply(lambda row: 
        f"Status: Churned<br>" +
        f"Session: {row['Session_Duration_Avg']:.1f} min<br>" +
        f"Order Value: ${row['Average_Order_Value']:.2f}<br>" +
        f"Purchases: {row['Total_Purchases']:.0f}<br>" +
        f"LTV: ${row['Lifetime_Value']:.2f}",
        axis=1
    ),
    hovertemplate='%{text}<extra></extra>',
    visible=True
))

# Create dropdown buttons (horizontal layout)
fig.update_layout(
    updatemenus=[
        dict(
            buttons=list([
                dict(
                    label="Both",
                    method="update",
                    args=[{"visible": [True, True]},
                          {"title": "3D Analysis: High-Value Retention Sweet Spot<br><sub>Showing: Both Active & Churned | Bubble Size = Lifetime Value</sub>"}]
                ),
                dict(
                    label="Active Only",
                    method="update",
                    args=[{"visible": [True, False]},
                          {"title": "3D Analysis: High-Value Retention Sweet Spot<br><sub>Showing: Active Customers Only | Bubble Size = Lifetime Value</sub>"}]
                ),
                dict(
                    label="Churned Only",
                    method="update",
                    args=[{"visible": [False, True]},
                          {"title": "3D Analysis: High-Value Retention Sweet Spot<br><sub>Showing: Churned Customers Only | Bubble Size = Lifetime Value</sub>"}]
                )
            ]),
            type="buttons",  # ‚Üê Changed to buttons (horizontal)
            direction="right",  # ‚Üê Horizontal layout
            pad={"r": 10, "t": 10},
            showactive=True,
            x=0.77,  
            xanchor="right",
            y=0.99,  
            yanchor="top",
            bgcolor="white",
            bordercolor="gray",
            borderwidth=2,
            font=dict(size=11)
        )
    ]
)

# Update scene layout
fig.update_layout(
    scene=dict(
        xaxis=dict(
            title='Session Duration (Percentile)',
            backgroundcolor='rgb(230, 230, 230)',
            gridcolor='white',
            range=[0, 100]
        ),
        yaxis=dict(
            title='Order Value (Percentile)',
            backgroundcolor='rgb(230, 230, 230)',
            gridcolor='white',
            range=[0, 100]
        ),
        zaxis=dict(
            title='Purchase Frequency (Percentile)',
            backgroundcolor='rgb(230, 230, 230)',
            gridcolor='white',
            range=[0, 100]
        ),
        camera=dict(
            eye=dict(x=1.5, y=1.5, z=1.3)
        )
    ),
    title='3D Analysis: High-Value Retention Sweet Spot<br><sub>Session Duration √ó Order Value √ó Purchase Frequency (All Percentile Scale)</sub>',
    font=dict(size=12),
    height=750,
    margin=dict(l=50, r=50, b=80, t=100),
    showlegend=False,
    # Two separate legend boxes side by side
    annotations=[
        # Left box: Bubble Size
        dict(
            text='<b>Bubble Size</b><br>' +
                 '<b>(Lifetime Value)</b><br>' +
                 f'‚óã Small:  < ${plot_df["Lifetime_Value"].quantile(0.33):.0f}<br>' +
                 f'‚óê Medium:  ${plot_df["Lifetime_Value"].quantile(0.33):.0f}-${plot_df["Lifetime_Value"].quantile(0.67):.0f}<br>' +
                 f'‚óè Large:  > ${plot_df["Lifetime_Value"].quantile(0.67):.0f}',
            xref="paper",
            yref="paper",
            x=0.01,
            y=1.03,
            xanchor="left",
            yanchor="top",
            showarrow=False,
            bgcolor="rgba(255, 255, 255, 0.9)",
            bordercolor="gray",
            borderwidth=1.5,
            borderpad=10,
            font=dict(size=10),
            align="left"
        ),
        # Right box: Churn Status (next to bubble size)
        dict(
            text='<b>Churn Status</b><br><br>' +
                 '<span style="color:#2ECC71; font-size:16px">‚óè</span> Active<br>' +
                 '<span style="color:#E74C3C; font-size:16px">‚óè</span> Churned',
            xref="paper",
            yref="paper",
            x=0.24,  
            y=1.03,
            xanchor="left",
            yanchor="top",
            showarrow=False,
            bgcolor="rgba(255, 255, 255, 0.9)",
            bordercolor="gray",
            borderwidth=1.5,
            borderpad=10,
            font=dict(size=10),
            align="left"
        )
    ],
    template=PLOTLY_TEMPLATE
)

fig.show()

# Save
fig.write_html('../visualizations/viz3_3d_golden_sweet_spot_filtered.html')








# Prepare data
engagement_df = df[[
    'Session_Duration_Avg',
    'Pages_Per_Session',
    'Login_Frequency',
    'Churned',
    'Loyalty_Segment'
]].dropna().copy()

# Sample for performance
if len(engagement_df) > 2000:
    engagement_sample = engagement_df.sample(n=2000, random_state=42)
    print(f"Sampled {len(engagement_sample):,} records")
else:
    engagement_sample = engagement_df

engagement_sample['Churn_Status'] = engagement_sample['Churned'].map({0: 'Active', 1: 'Churned'})

# Create scatter matrix
fig = px.scatter_matrix(
    engagement_sample,
    dimensions=['Session_Duration_Avg', 'Pages_Per_Session', 'Login_Frequency'],
    color='Churn_Status',
    color_discrete_map={
        'Active': COLOR_PALETTE['active'],
        'Churned': COLOR_PALETTE['churned']
    },
    opacity=0.5,
    title='Engagement Quality Matrix<br><sub>Session Duration √ó Pages Per Session √ó Login Frequency</sub>',
    labels={
        'Session_Duration_Avg': 'Session Duration',
        'Pages_Per_Session': 'Pages/Session',
        'Login_Frequency': 'Login Freq'
    },
    template=PLOTLY_TEMPLATE,
    height=700
)

# Update layout
fig.update_layout(
    font=dict(size=11),
    showlegend=True,
    legend=dict(
        title_text='Churn Status',
        orientation="v",
        yanchor="top",
        y=0.99,
        xanchor="right",
        x=0.99,
        bgcolor="rgba(255, 255, 255, 0.9)",
        bordercolor="gray",
        borderwidth=1
    )
)

# Update diagonal to show distributions
fig.update_traces(diagonal_visible=True, showupperhalf=False)

fig.show()
fig.write_html('../visualizations/viz4_engagement_quality_matrix.html')





# Prepare data
analysis_df = df[[
    'Signup_Quarter',
    'Loyalty_Segment',
    'Returner_Type',
    'Discount_Usage_Rate',
    'Total_Purchases'
]].dropna().copy()

# Define orders
loyalty_order = ['Negative', 'Occasional', 'Regular', 'Frequent', 'Loyal', 'Power User']
returner_order = ['Keeper', 'Normal', 'Frequent Returner', 'High Risk', 'Abusive']

loyalty_existing = [seg for seg in loyalty_order if seg in analysis_df['Loyalty_Segment'].unique()]
returner_existing = [ret for ret in returner_order if ret in analysis_df['Returner_Type'].unique()]

quarters = sorted(analysis_df['Signup_Quarter'].unique())

# Calculate overall averages
mean_discount = analysis_df['Discount_Usage_Rate'].mean()
mean_purchases = analysis_df['Total_Purchases'].mean()



# Create subplots with shared x-axis
fig = make_subplots(
    rows=2, cols=1,
    shared_xaxes=True,
    vertical_spacing=0.03, # spacing between two sub plots
    subplot_titles=('Discount Usage Rate (%)', 'Total Purchases'),
    row_heights=[0.3, 0.7]
)

# ============================================================================
# OPTION A: X-axis = Loyalty Segment
# ============================================================================

# Top chart: Discount Usage by Loyalty
for quarter in quarters:
    quarter_data = analysis_df[analysis_df['Signup_Quarter'] == quarter]
    
    discount_by_loyalty = []
    for loyalty in loyalty_existing:
        values = quarter_data[quarter_data['Loyalty_Segment'] == loyalty]['Discount_Usage_Rate']
        discount_by_loyalty.append(values.tolist() if len(values) > 0 else [])
    
    fig.add_trace(
        go.Violin(
            y=[val for sublist in discount_by_loyalty for val in sublist],
            x=[loyalty for i, loyalty in enumerate(loyalty_existing) for _ in discount_by_loyalty[i]],
            name=quarter,
            marker_color=px.colors.qualitative.Set2[quarters.index(quarter) % len(px.colors.qualitative.Set2)],
            legendgroup=quarter,
            showlegend=True,
            offsetgroup=quarter,
            scalemode='width',  
            meanline_visible=True,
            # box_visible=True,  # inside box
            points=False  # not showing all points  
        ),
        row=1, col=1
    )

# Bottom chart: Total Purchases by Loyalty
for quarter in quarters:
    quarter_data = analysis_df[analysis_df['Signup_Quarter'] == quarter]
    
    purchases_by_loyalty = []
    for loyalty in loyalty_existing:
        values = quarter_data[quarter_data['Loyalty_Segment'] == loyalty]['Total_Purchases']
        purchases_by_loyalty.append(values.tolist() if len(values) > 0 else [])
    
    fig.add_trace(
        go.Violin(
            y=[val for sublist in purchases_by_loyalty for val in sublist],
            x=[loyalty for i, loyalty in enumerate(loyalty_existing) for _ in purchases_by_loyalty[i]],
            name=quarter,
            marker_color=px.colors.qualitative.Set2[quarters.index(quarter) % len(px.colors.qualitative.Set2)],
            legendgroup=quarter,
            showlegend=False,
            offsetgroup=quarter,
            scalemode='width',  
            meanline_visible=True,
            # box_visible=True,  # inside box
            points=False  # not showing all points  
        ),
        row=2, col=1
    )

# ============================================================================
# OPTION B: X-axis = Returner Type (hidden initially)
# ============================================================================

# Top chart: Discount Usage by Returner Type
for quarter in quarters:
    quarter_data = analysis_df[analysis_df['Signup_Quarter'] == quarter]
    
    discount_by_returner = []
    for returner in returner_existing:
        values = quarter_data[quarter_data['Returner_Type'] == returner]['Discount_Usage_Rate']
        discount_by_returner.append(values.tolist() if len(values) > 0 else [])
    
    fig.add_trace(
        go.Violin(
            y=[val for sublist in discount_by_returner for val in sublist],
            x=[returner for i, returner in enumerate(returner_existing) for _ in discount_by_returner[i]],
            name=quarter,
            marker_color=px.colors.qualitative.Set2[quarters.index(quarter) % len(px.colors.qualitative.Set2)],
            legendgroup=quarter,
            showlegend=True,
            offsetgroup=quarter,
            visible=False,  # Hidden initially
            scalemode='width',  
            meanline_visible=True,
            # box_visible=True,  # inside box
            points=False  # not showing all points    
        ),
        row=1, col=1
    )
    # # Add reference lines
    # fig.add_hline(y=mean_discount, line_dash="dash", line_color="red", line_width=2, 
    #             opacity=0.7, row=1, col=1)

# Bottom chart: Total Purchases by Returner Type
for quarter in quarters:
    quarter_data = analysis_df[analysis_df['Signup_Quarter'] == quarter]
    
    purchases_by_returner = []
    for returner in returner_existing:
        values = quarter_data[quarter_data['Returner_Type'] == returner]['Total_Purchases']
        purchases_by_returner.append(values.tolist() if len(values) > 0 else [])
    
    fig.add_trace(
        go.Violin(
            y=[val for sublist in purchases_by_returner for val in sublist],
            x=[returner for i, returner in enumerate(returner_existing) for _ in purchases_by_returner[i]],
            name=quarter,
            marker_color=px.colors.qualitative.Set2[quarters.index(quarter) % len(px.colors.qualitative.Set2)],
            legendgroup=quarter,
            showlegend=False,
            offsetgroup=quarter,
            visible=False,  # Hidden initially
            scalemode='width',  
            meanline_visible=True,
            # box_visible=True,  # inside box
            points=False  # not showing all points   
        ),
        row=2, col=1
    )



# ============================================================================
# Create dropdown for X-axis switching
# ============================================================================

# Calculate visibility for each option
n_quarters = len(quarters)
total_traces = len(fig.data)

# Option A visibility: First 2*n_quarters traces (Loyalty)
visibility_loyalty = [True] * (2 * n_quarters) + [False] * (2 * n_quarters)

# Option B visibility: Last 2*n_quarters traces (Returner)
visibility_returner = [False] * (2 * n_quarters) + [True] * (2 * n_quarters)

fig.update_layout(
    updatemenus=[
        dict(
            buttons=[
                dict(
                    label="By Loyalty Segment",
                    method="update",
                    args=[
                        {"visible": visibility_loyalty},
                        {
                            "xaxis.title": "Loyalty Segment (Based on Total Purchases)",
                            "xaxis2.title": "Loyalty Segment (Based on Total Purchases)",
                            # Add annotations update here
                            "annotations": [
                                fig.layout.annotations[0],  # Keep subplot title 1
                                fig.layout.annotations[1],  # Keep subplot title 2
                                # # Overall Average
                                # dict(
                                #     xref="paper", yref="y",
                                #     x=0.98, y=mean_discount + 5,
                                #     text=f"Overall Avg<br><b>{mean_discount:.1f}%</b>",
                                #     showarrow=False,
                                #     font=dict(size=11, color="red", weight="bold"),
                                #     bgcolor="rgba(255, 255, 255, 0.9)",
                                #     bordercolor="red", borderwidth=1.5, borderpad=5,
                                #     xanchor="right", yanchor="bottom"
                                # ),
                                # Loyalty definition
                                dict(
                                    text='<b>Loyalty Segment Definitions</b><br>' +
                                         f'Negative: < 0  |  Occasional: < {df["Total_Purchases"].quantile(0.25):.0f}  |  ' +
                                         f'Regular: {df["Total_Purchases"].quantile(0.25):.0f}-{df["Total_Purchases"].quantile(0.50):.0f}<br>' +
                                         f'Frequent: {df["Total_Purchases"].quantile(0.50):.0f}-{df["Total_Purchases"].quantile(0.75):.0f}  |  ' +
                                         f'Loyal: {df["Total_Purchases"].quantile(0.75):.0f}-{df["Total_Purchases"].quantile(0.90):.0f}  |  ' +
                                         f'Power User: > {df["Total_Purchases"].quantile(0.90):.0f}',
                                    xref="paper", yref="paper",
                                    x=0.5, y=-0.08,
                                    xanchor="center", yanchor="top",
                                    showarrow=False,
                                    bgcolor="rgba(255, 255, 255, 0.95)",
                                    bordercolor="gray", borderwidth=1.5, borderpad=8,
                                    font=dict(size=10), align="center"
                                )
                            ]
                        }
                    ]
                ),
                dict(
                    label="By Returner Type",
                    method="update",
                    args=[
                        {"visible": visibility_returner},
                        {
                            "xaxis.title": "Returner Type (Based on Returns Rate)",
                            "xaxis2.title": "Returner Type (Based on Returns Rate)",
                            # Add annotations update here
                            "annotations": [
                                fig.layout.annotations[0],  # Keep subplot title 1
                                fig.layout.annotations[1],  # Keep subplot title 2
                                # Overall Average
                                # dict(
                                #     xref="paper", yref="y",
                                #     x=0.98, y=mean_discount + 5,
                                #     text=f"Overall Avg<br><b>{mean_discount:.1f}%</b>",
                                #     showarrow=False,
                                #     font=dict(size=11, color="red", weight="bold"),
                                #     bgcolor="rgba(255, 255, 255, 0.9)",
                                #     bordercolor="red", borderwidth=1.5, borderpad=5,
                                #     xanchor="right", yanchor="bottom"
                                # ),
                                # Returner definition
                                dict(
                                    text='<b>Returner Type Definitions</b><br>' +
                                         'Keeper: 0-5%  |  Normal: 5-20%  |  Frequent: 20-40%  |  High Risk: 40-80%  |  Abusive: >80%',
                                    xref="paper", yref="paper",
                                    x=0.5, y=-0.08,
                                    xanchor="center", yanchor="top",
                                    showarrow=False,
                                    bgcolor="rgba(255, 255, 255, 0.95)",
                                    bordercolor="gray", borderwidth=1.5, borderpad=8,
                                    font=dict(size=10), align="center"
                                )
                            ]
                        }
                    ]
                )
            ],
            type="buttons",
            direction="right",
            x=0.8,
            xanchor="center",
            y=1.08,
            yanchor="top",
            bgcolor="white",
            bordercolor="gray",
            borderwidth=2,
            font=dict(size=11),
            showactive=True
        )
    ]
)

# Update layout
fig.update_layout(
    title='Discount Dependency & Purchase Volume Analysis<br><sub>Switch X-axis to compare by Loyalty vs Return Behavior</sub>',
    height=800,
    showlegend=True,
    violinmode='group', # side by side, not overlapping. same as boxmode='group'
    legend=dict(
        title_text='Signup Quarter',
        orientation="v",
        yanchor="top",
        y=0.6,
        xanchor="right",
        x=0.2,
        bgcolor="rgba(255, 255, 255, 0.9)",
        bordercolor="gray",
        borderwidth=1
    ),
    template='plotly_white',
    font=dict(size=11),
    margin=dict(l=80, r=80, b=140, t=100)
)

# Update axes
fig.update_xaxes(title_text="Loyalty Segment (Based on Total Purchases)", row=2, col=1, tickangle=0)
fig.update_yaxes(title_text="Discount Usage Rate (%)", row=1, col=1)
fig.update_yaxes(title_text="Total Purchases", row=2, col=1)

fig.show()
fig.write_html('../visualizations/viz5_dual_chart_dynamic.html')











# Prepare data
breaking_point_df = df[[
    'Customer_Service_Calls',
    'Cart_Abandonment_Rate',
    'Total_Purchases',
    'Churned',
    'Lifetime_Value'
]].dropna().copy()

# Sample for performance
if len(breaking_point_df) > 2000:
    breaking_sample = breaking_point_df.sample(n=2000, random_state=42)
    print(f"Sampled {len(breaking_sample):,} records")
else:
    breaking_sample = breaking_point_df

breaking_sample['Churn_Status'] = breaking_sample['Churned'].map({0: 'Active', 1: 'Churned'})

# Create scatter matrix
fig = px.scatter_matrix(
    breaking_sample,
    dimensions=['Customer_Service_Calls', 'Cart_Abandonment_Rate', 'Total_Purchases'],
    color='Churn_Status',
    color_discrete_map={
        'Active': COLOR_PALETTE['active'],
        'Churned': COLOR_PALETTE['churned']
    },
    size='Lifetime_Value',
    size_max=10,
    opacity=0.5,
    title='The Breaking Point Analysis<br><sub>Customer Service Calls √ó Cart Abandonment √ó Purchase Volume (Size = LTV)</sub>',
    labels={
        'Customer_Service_Calls': 'Service Calls',
        'Cart_Abandonment_Rate': 'Cart Abandon %',
        'Total_Purchases': 'Purchases'
    },
    template=PLOTLY_TEMPLATE,
    height=700
)

# Update layout
fig.update_layout(
    font=dict(size=11),
    showlegend=True,
    legend=dict(
        title_text='Churn Status',
        orientation="v",
        yanchor="top",
        y=0.99,
        xanchor="right",
        x=0.99,
        bgcolor="rgba(255, 255, 255, 0.9)",
        bordercolor="gray",
        borderwidth=1
    )
)

# Update diagonal
fig.update_traces(diagonal_visible=True, showupperhalf=False)

fig.show()
fig.write_html('../visualizations/viz6_breaking_point_matrix.html')

# Identify critical thresholds
print("\nüö® CRITICAL THRESHOLDS:")

churned = breaking_point_df[breaking_point_df['Churned'] == 1]
active = breaking_point_df[breaking_point_df['Churned'] == 0]

print(f"\nCustomer Service Calls:")
print(f"  ‚Ä¢ Active avg: {active['Customer_Service_Calls'].mean():.1f}")
print(f"  ‚Ä¢ Churned avg: {churned['Customer_Service_Calls'].mean():.1f}")
print(f"  ‚Ä¢ Threshold: >{churned['Customer_Service_Calls'].quantile(0.25):.0f} calls = High risk")

print(f"\nCart Abandonment Rate:")
print(f"  ‚Ä¢ Active avg: {active['Cart_Abandonment_Rate'].mean():.1f}%")
print(f"  ‚Ä¢ Churned avg: {churned['Cart_Abandonment_Rate'].mean():.1f}%")
print(f"  ‚Ä¢ Threshold: >{churned['Cart_Abandonment_Rate'].quantile(0.25):.0f}% = High risk")








# Prepare data
churn_path_df = df[[
    'Customer_Service_Calls',
    'Cart_Abandonment_Rate',
    'Login_Frequency',
    'Days_Since_Last_Purchase',
    'Session_Duration_Avg',
    'Churned'
]].copy()

# Sample for performance
if len(churn_path_df) > 3000:
    sample_size = 3000
    churn_path_sample = churn_path_df.sample(n=sample_size, random_state=42)
    print(f"\nSampled {sample_size:,} records for visualization clarity")
else:
    churn_path_sample = churn_path_df
    print(f"\nUsing all {len(churn_path_sample):,} records")

# Normalize features
from sklearn.preprocessing import MinMaxScaler

features_to_normalize = [
    'Customer_Service_Calls',
    'Cart_Abandonment_Rate',
    'Login_Frequency',
    'Days_Since_Last_Purchase',
    'Session_Duration_Avg'
]

scaler = MinMaxScaler()
churn_path_normalized = churn_path_sample.copy()
churn_path_normalized[features_to_normalize] = scaler.fit_transform(
    churn_path_sample[features_to_normalize]
)

# Separate active and churned
active_data = churn_path_normalized[churn_path_normalized['Churned'] == 0]
churned_data = churn_path_normalized[churn_path_normalized['Churned'] == 1]

# Create figure with THREE traces (Active, Churned, Both)
fig = go.Figure()

# Trace 1: Both (combined)
fig.add_trace(go.Parcoords(
    line=dict(
        color=churn_path_normalized['Churned'],
        colorscale=[[0, COLOR_PALETTE['active']], [1, COLOR_PALETTE['churned']]],
        showscale=True,
        cmin=0,
        cmax=1,
        colorbar=dict(
            title="Status",
            tickvals=[0, 1],
            ticktext=['Active', 'Churned'],
            len=0.4,
            thickness=15,
            x=1.12
        )
    ),
    dimensions=[
        dict(
            range=[0, 1],
            label='Service<br>Calls',
            values=churn_path_normalized['Customer_Service_Calls'],
            tickvals=[0, 0.5, 1],
            ticktext=['Low', 'Med', 'High']
        ),
        dict(
            range=[0, 1],
            label='Cart<br>Abandon %',
            values=churn_path_normalized['Cart_Abandonment_Rate'],
            tickvals=[0, 0.5, 1],
            ticktext=['Low', 'Med', 'High']
        ),
        dict(
            range=[0, 1],
            label='Login<br>Frequency',
            values=churn_path_normalized['Login_Frequency'],
            tickvals=[0, 0.5, 1],
            ticktext=['Low', 'Med', 'High']
        ),
        dict(
            range=[0, 1],
            label='Days Since<br>Purchase',
            values=churn_path_normalized['Days_Since_Last_Purchase'],
            tickvals=[0, 0.5, 1],
            ticktext=['Recent', 'Med', 'Long']
        ),
        dict(
            range=[0, 1],
            label='Session<br>Duration',
            values=churn_path_normalized['Session_Duration_Avg'],
            tickvals=[0, 0.5, 1],
            ticktext=['Short', 'Med', 'Long']
        )
    ],
    visible=True,
    name='Both'
))

# Trace 2: Active only
fig.add_trace(go.Parcoords(
    line=dict(
        color=COLOR_PALETTE['active'],
        showscale=False
    ),
    dimensions=[
        dict(range=[0, 1], label='Service<br>Calls', values=active_data['Customer_Service_Calls'],
             tickvals=[0, 0.5, 1], ticktext=['Low', 'Med', 'High']),
        dict(range=[0, 1], label='Cart<br>Abandon %', values=active_data['Cart_Abandonment_Rate'],
             tickvals=[0, 0.5, 1], ticktext=['Low', 'Med', 'High']),
        dict(range=[0, 1], label='Login<br>Frequency', values=active_data['Login_Frequency'],
             tickvals=[0, 0.5, 1], ticktext=['Low', 'Med', 'High']),
        dict(range=[0, 1], label='Days Since<br>Purchase', values=active_data['Days_Since_Last_Purchase'],
             tickvals=[0, 0.5, 1], ticktext=['Recent', 'Med', 'Long']),
        dict(range=[0, 1], label='Session<br>Duration', values=active_data['Session_Duration_Avg'],
             tickvals=[0, 0.5, 1], ticktext=['Short', 'Med', 'Long'])
    ],
    visible=False,
    name='Active'
))

# Trace 3: Churned only
fig.add_trace(go.Parcoords(
    line=dict(
        color=COLOR_PALETTE['churned'],
        showscale=False
    ),
    dimensions=[
        dict(range=[0, 1], label='Service<br>Calls', values=churned_data['Customer_Service_Calls'],
             tickvals=[0, 0.5, 1], ticktext=['Low', 'Med', 'High']),
        dict(range=[0, 1], label='Cart<br>Abandon %', values=churned_data['Cart_Abandonment_Rate'],
             tickvals=[0, 0.5, 1], ticktext=['Low', 'Med', 'High']),
        dict(range=[0, 1], label='Login<br>Frequency', values=churned_data['Login_Frequency'],
             tickvals=[0, 0.5, 1], ticktext=['Low', 'Med', 'High']),
        dict(range=[0, 1], label='Days Since<br>Purchase', values=churned_data['Days_Since_Last_Purchase'],
             tickvals=[0, 0.5, 1], ticktext=['Recent', 'Med', 'Long']),
        dict(range=[0, 1], label='Session<br>Duration', values=churned_data['Session_Duration_Avg'],
             tickvals=[0, 0.5, 1], ticktext=['Short', 'Med', 'Long'])
    ],
    visible=False,
    name='Churned'
))

# Add dropdown buttons (horizontal)
fig.update_layout(
    updatemenus=[
        dict(
            buttons=[
                dict(
                    label="Both",
                    method="update",
                    args=[{"visible": [True, False, False]}]
                ),
                dict(
                    label="Active Only",
                    method="update",
                    args=[{"visible": [False, True, False]}]
                ),
                dict(
                    label="Churned Only",
                    method="update",
                    args=[{"visible": [False, False, True]}]
                )
            ],
            type="buttons",
            direction="right",  # Horizontal
            x=1.0,
            xanchor="right",
            y=1.3,
            yanchor="top",
            bgcolor="white",
            bordercolor="gray",
            borderwidth=2,
            font=dict(size=11),
            showactive=True
        )
    ],
    title='Churn Journey Path Analysis<br><sub>Trace the metrics pathway (Green = Active, Red = Churned)</sub>',
    font=dict(size=12),
    height=600,
    margin=dict(l=100, r=150, t=200, b=50),
    template=PLOTLY_TEMPLATE
)

fig.show()

# Save
fig.write_html('../visualizations/viz7_churn_journey_parallel.html')


# Statistical analysis
print("\nüìä Path Comparison - Churned vs Active:")
churned_avg = churn_path_df[churn_path_df['Churned'] == 1][features_to_normalize].mean()
active_avg = churn_path_df[churn_path_df['Churned'] == 0][features_to_normalize].mean()

comparison = pd.DataFrame({
    'Metric': features_to_normalize,
    'Churned_Avg': [churned_avg[col] for col in features_to_normalize],
    'Active_Avg': [active_avg[col] for col in features_to_normalize],
    'Difference': [churned_avg[col] - active_avg[col] for col in features_to_normalize]
})
print(comparison.to_string(index=False))









